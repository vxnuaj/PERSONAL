
> *Check it out on substack*

https://x.com/ToKTeacher/status/1800349959054840122

*should not scared of a computer that passes the Turing test (that's mimesis, not true human intelligence with creativity.), should be scared of one that intentionally fails it*

despite computers being able to do surgeries ((neuralink)), steer spaceships ((saturn-v, gemini guidance computer)), fold proteins ((alpha fold)), beat elite go players ((alphago / alphazero)), yet they struggle to accurately process natural language. the gap might be in creativity, intuition, and understanding. the former can be based on more discrete unambiguous steps while the latter requires depth and understanding to be fully (reliable).


in a sense, whenever we query an llm about a question, it's giving us the consensus of the data it was trained upon, not novel ideas or conjectures backed by creativity[^1]

if human's are purely algorithmic at the quantum level (which i'm biased to believe, given that it's a better explanation when compared to the supernatural) then creativity can be reverse engineered, then it's possible to create a type of agi that has a type of creativity.[^2]

creativity and novel ideas are a type of disobedience to the status quo, going based of the general consensus isn't how we built new ideas. agi needs to disobey.

**on the imitation game / turing test:**
> *But that's mimesis. Humans & intelligence aren't a byproduct of mimesis, they are a byproduct of understanding through creativity (disobedience) and error correction. If a computer is mimetic, it can't disobey and then it can't be creative and then it can't error-correct for itself to create it's own knowledge and intelligence through understanding. 
> 
> If a machines "thought processes" aren't able to understand the underlying concepts and are just mimetic, I don't believe that's intelligence.


Ray Kurzweil believes that in 2029, the Turing test will be passed by AI.

[^1]: and creativity is essential for progress. no creativity, no new ideas or conjectures to solve unique problems, no failure, then no error-correction, then stagnation. creativity is the reason human's thrived, it's the reason agi might thrive as well someday.

[^2]: scaling laws aren't the way, unless emergent properties are true, continuing to predict the next token at scale won't do jack shit.