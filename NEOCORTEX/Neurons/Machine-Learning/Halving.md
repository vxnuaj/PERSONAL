A means for [[Learning Rate Decay]], defined as:

$\alpha = \frac{\alpha}{2}$

where $\alpha$ is halved after a set number of epochs.

This *halving* can be replaced instead by a division by any number, depending on how you might want to schedule the learning rate.