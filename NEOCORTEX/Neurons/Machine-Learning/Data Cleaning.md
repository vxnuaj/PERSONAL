

Key aspects of machine learning workflow depend on clean data.

**Observation:** an instance of a dataset (row, column, datapoint)
**Labels**: Output variable, aiming to be predicted
**Algorithm:** The computer program that defines how a model estimates the true labels
**Features**: Each important observation there is for a set of observations
**Model**: The hypothesized relationships between the observations and the data (represented by parameters, $\theta$).

**Typical Problems**:
- Too much data - where there's a data engineering problem, unable to isolate the important datapoints, not prepared for real model training.
- Lack of data - Not enough data to train a model
- Bad data - corrupted data, misrepresented the true scenario intended to model


**Messy Data**:
If a specific instance, a row or column or specific datapoint, is corrupted in the sense that it's misrepresenting the intended datapoint.

- Duplicate or unneeded data
- Inconsistent text and typos
- Missing data
- Data sourcing issues

[[Duplicate Data]] | [[Missing Data]] | [[Outliers]]

