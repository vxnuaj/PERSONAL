
A TPU is an AI accelerator [[ASIC]] designed by Google for accelerating the training of their deep learning architectures using their proprietary [[Tensorflow]] software.

They contain thousands of [[multiply-accumulators]] that are connected to each other to form a [[systolic array]] unit called a matrix multiply unit ([[MXU]]) that can perform operations in parallel.

These TPUs train models more efficiently as they use hardware that's specifically designed for performing large matrix operations found in deep learning algorithms.