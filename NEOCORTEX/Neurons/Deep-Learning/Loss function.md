---
tags: mathematics
---
The loss function of a neural network is a metric that determines error between a prediction and a true output value at a given value.

Whilst training a neural network, the average value of the loss function, called a [[cost function]] is minimized to maximize the accuracy of a model.

This loss value is of important use during [[gradient descent]] as the [[update rule]] is based on taking the gradient of the loss with respect to a specific parameter.

Some types of loss functions include:
- [[Sigmoid]]
- [[Mean Squared Error]]
- [[Categorical Cross Entropy Loss]]
